2025-11-04 08:05:18 Training with configuration:
2025-11-04 08:05:18 data:
2025-11-04 08:05:18   bbox_margin: 20
2025-11-04 08:05:18   colormode: RGB
2025-11-04 08:05:18   inference:
2025-11-04 08:05:18     normalize_images: True
2025-11-04 08:05:18   train:
2025-11-04 08:05:18     affine:
2025-11-04 08:05:18       p: 0.5
2025-11-04 08:05:18       rotation: 30
2025-11-04 08:05:18       scaling: [0.5, 1.25]
2025-11-04 08:05:18       translation: 0
2025-11-04 08:05:18     crop_sampling:
2025-11-04 08:05:18       width: 448
2025-11-04 08:05:18       height: 448
2025-11-04 08:05:18       max_shift: 0.1
2025-11-04 08:05:18       method: hybrid
2025-11-04 08:05:18     gaussian_noise: 12.75
2025-11-04 08:05:18     motion_blur: True
2025-11-04 08:05:18     normalize_images: True
2025-11-04 08:05:18 device: auto
2025-11-04 08:05:18 inference:
2025-11-04 08:05:18   multithreading:
2025-11-04 08:05:18     enabled: True
2025-11-04 08:05:18     queue_length: 4
2025-11-04 08:05:18     timeout: 30.0
2025-11-04 08:05:18   compile:
2025-11-04 08:05:18     enabled: False
2025-11-04 08:05:18     backend: inductor
2025-11-04 08:05:18   autocast:
2025-11-04 08:05:18     enabled: False
2025-11-04 08:05:18 metadata:
2025-11-04 08:05:18   project_path: D:\pycode\DeepLabCut\Testcore-Mackenzie-2025-11-04
2025-11-04 08:05:18   pose_config_path: D:\pycode\DeepLabCut\Testcore-Mackenzie-2025-11-04\dlc-models-pytorch\iteration-0\TestcoreNov4-trainset80shuffle1\train\pytorch_config.yaml
2025-11-04 08:05:18   bodyparts: ['bodypart1', 'bodypart2', 'bodypart3', 'objectA']
2025-11-04 08:05:18   unique_bodyparts: []
2025-11-04 08:05:18   individuals: ['animal']
2025-11-04 08:05:18   with_identity: None
2025-11-04 08:05:18 method: bu
2025-11-04 08:05:18 model:
2025-11-04 08:05:18   backbone:
2025-11-04 08:05:18     type: ResNet
2025-11-04 08:05:18     model_name: resnet50_gn
2025-11-04 08:05:18     output_stride: 16
2025-11-04 08:05:18     freeze_bn_stats: False
2025-11-04 08:05:18     freeze_bn_weights: False
2025-11-04 08:05:18   backbone_output_channels: 2048
2025-11-04 08:05:18   heads:
2025-11-04 08:05:18     bodypart:
2025-11-04 08:05:18       type: HeatmapHead
2025-11-04 08:05:18       weight_init: normal
2025-11-04 08:05:18       predictor:
2025-11-04 08:05:18         type: HeatmapPredictor
2025-11-04 08:05:18         apply_sigmoid: False
2025-11-04 08:05:18         clip_scores: True
2025-11-04 08:05:18         location_refinement: True
2025-11-04 08:05:18         locref_std: 7.2801
2025-11-04 08:05:18       target_generator:
2025-11-04 08:05:18         type: HeatmapGaussianGenerator
2025-11-04 08:05:18         num_heatmaps: 4
2025-11-04 08:05:18         pos_dist_thresh: 17
2025-11-04 08:05:18         heatmap_mode: KEYPOINT
2025-11-04 08:05:18         gradient_masking: False
2025-11-04 08:05:18         generate_locref: True
2025-11-04 08:05:18         locref_std: 7.2801
2025-11-04 08:05:18       criterion:
2025-11-04 08:05:18         heatmap:
2025-11-04 08:05:18           type: WeightedMSECriterion
2025-11-04 08:05:18           weight: 1.0
2025-11-04 08:05:18         locref:
2025-11-04 08:05:18           type: WeightedHuberCriterion
2025-11-04 08:05:18           weight: 0.05
2025-11-04 08:05:18       heatmap_config:
2025-11-04 08:05:18         channels: [2048, 4]
2025-11-04 08:05:18         kernel_size: [3]
2025-11-04 08:05:18         strides: [2]
2025-11-04 08:05:18       locref_config:
2025-11-04 08:05:18         channels: [2048, 8]
2025-11-04 08:05:18         kernel_size: [3]
2025-11-04 08:05:18         strides: [2]
2025-11-04 08:05:18 net_type: resnet_50
2025-11-04 08:05:18 runner:
2025-11-04 08:05:18   type: PoseTrainingRunner
2025-11-04 08:05:18   gpus: None
2025-11-04 08:05:18   key_metric: test.mAP
2025-11-04 08:05:18   key_metric_asc: True
2025-11-04 08:05:18   eval_interval: 10
2025-11-04 08:05:18   optimizer:
2025-11-04 08:05:18     type: AdamW
2025-11-04 08:05:18     params:
2025-11-04 08:05:18       lr: 0.0005
2025-11-04 08:05:18   scheduler:
2025-11-04 08:05:18     type: LRListScheduler
2025-11-04 08:05:18     params:
2025-11-04 08:05:18       lr_list: [[0.0001], [1e-05]]
2025-11-04 08:05:18       milestones: [90, 120]
2025-11-04 08:05:18   snapshots:
2025-11-04 08:05:18     max_snapshots: 5
2025-11-04 08:05:18     save_epochs: 25
2025-11-04 08:05:18     save_optimizer_state: False
2025-11-04 08:05:18 train_settings:
2025-11-04 08:05:18   batch_size: 8
2025-11-04 08:05:18   dataloader_workers: 0
2025-11-04 08:05:18   dataloader_pin_memory: False
2025-11-04 08:05:18   display_iters: 2
2025-11-04 08:05:18   epochs: 3
2025-11-04 08:05:18   seed: 42
2025-11-04 08:05:18 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-11-04 08:05:22 HTTP Request: HEAD https://huggingface.co/timm/resnet50_gn.a1h_in1k/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-11-04 08:05:22 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-04 08:05:22 Data Transforms:
2025-11-04 08:05:22   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-11-04 08:05:22   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-11-04 08:05:22 Using 4 images and 1 for testing
2025-11-04 08:05:22 
Starting pose model training...
--------------------------------------------------
2025-11-04 08:05:27 Epoch 1/3 (lr=0.0005), train loss 0.01587
2025-11-04 08:05:30 Epoch 2/3 (lr=0.0005), train loss 0.01985
2025-11-04 08:05:34 Epoch 3/3 (lr=0.0005), train loss 0.01555
